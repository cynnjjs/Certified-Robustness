import tensorflow as tf
import numpy as np
import os 

from utils.get_model import get_model

## Bounds
from bounds.bounds_sdp import get_pairwise_loss
from bounds.bounds_spectral import bounds_spectral 
from bounds.bounds_fro import bounds_fro 

"""
Computes the loss for each bound
Takes as input: 
1. X_test --> To compute the current function values 
2. Y_test
3. FLAGS for defining the model 
"""

def compute_logits (X_test, Y_test, FLAGS):
## Step 1: Define the model 
## Step 2: Load the weights
## Step 3: Run the session to get the logits 

    x = tf.placeholder(tf.float32, [None, FLAGS.dimension])
    with tf.variable_scope("model_weights") as scope:
        scope.reuse_variables()
        y_model = get_model(x, FLAGS)


    sess = tf.InteractiveSession()
    saver = tf.train.Saver()
    ## Restoring the weights and dual variables 
    saver.restore(sess, FLAGS.msave + "-final")

    ## Running the graph 
    Logits, = sess.run([y_model], feed_dict={x:X_test})

    return Logits



"""
Takes as input:
 1. Logits
2. Bounds_matrix 
Returns the zero one and hinge loss 
"""
def compute_loss(Y_test, Logits, Bounds_matrix, epsilon, FLAGS):
## For every datapoint, compute hinge loss for max
    num_points = np.shape(Logits)[0]
    num_classes = FLAGS.num_classes
    Zo_loss = np.zeros([num_points, 1])
    Hinge_loss = np.zeros([num_points, 1])
    New_labels = np.zeros([num_points, 1])

    for i in range(num_points):
        ## Compute the label 
        label = np.argmax(Y_test[i, :])
        ## Compute max f(j) - f(true) after perturbation

        new_values = np.ravel(Logits[i, :]) - np.ravel(np.ones([num_classes, 1])*Logits[i, label]) + epsilon*np.ravel(Bounds_matrix[label, :])
        
        max_new_val = np.max(new_values)
        new_label = np.argmax(new_values)
        New_labels[i] = new_label

        if(max_new_val > 0):
            Zo_loss[i] = 1
        
        Hinge_loss[i] = max(0, 1 + max_new_val)
    
            
    
    return Zo_loss, Hinge_loss, New_labels



""" 
Restore the weights, and then save the weights
separately as a dictionary (two_layer)
and call the appropriate two_layer bounds 
Takes as input: 
a. X_test 
b. Y_test 
c. args["fsave"] + weights that has the weights
d. args["model"] : Model to build
e. args["results_dir"]: Directory inside which to add the loss files 
f. args["Epsilon"]: Range of epsilon to compute bounds over
"""

def bounds_main(X_test, Y_test, Epsilon, FLAGS):
    x = tf.placeholder(tf.float32, [None, FLAGS.dimension])
    y_ = tf.placeholder(tf.float32, [None, FLAGS.num_classes])

    with tf.variable_scope("model_weights") as scope:
        y_model = get_model(x, FLAGS)
        scope.reuse_variables()

    # If reg_type = first order, create the dual variables 
    if(FLAGS.reg_type == "first_order"):
        print("inside first order")
        with tf.variable_scope("dual") as scope:
            num_dual_variables = int( FLAGS.num_classes*(FLAGS.num_classes - 1)*0.5)
            init = np.random.normal(0, FLAGS.sd, [num_dual_variables, FLAGS.num_hidden + FLAGS.dimension + 1]);
            init = np.float32(init)
            c = tf.get_variable("dual", dtype = tf.float32, initializer = init)

    tvars = tf.trainable_variables()
    print(tvars)
    sess = tf.InteractiveSession()
    saver = tf.train.Saver()
    ## Restoring the weights
    

    saver.restore(sess, FLAGS.msave + "-final")
    
    w_fc1  = tvars[0]
    b_fc1 = tvars[1]
    w_fc2 = tvars[2]
    b_fc2 = tvars[3]
    W_fc1 = w_fc1.eval()
    B_fc1 = b_fc1.eval()
    W_fc2 = w_fc2.eval()
    B_fc2 = b_fc2.eval()        


    # Checking if dual variables are present
    if(FLAGS.reg_type == "first_order"):
        c = tvars[4];
        C = c.eval();
        model_weights= {'W_FC1':(W_fc1), 'B_FC1':B_fc1, 'W_FC2':np.transpose(W_fc2), 'B_FC2':B_fc2, 'dual':C}        
        
        SDP_matrix = np.zeros([FLAGS.num_classes, FLAGS.num_classes])
        for i_ in range(FLAGS.num_classes):
            for j_ in range(i_):
                ind = i_*(FLAGS.num_classes - 1) + j_
                SDP_matrix[i_, j_] = get_pairwise_loss(model_weights, i_, j_, FLAGS)
            
        # Scaling factor from the dual formulation 
        SDP_matrix = SDP_matrix*0.25;


    ## Created the dictionary of required weight matrices
    else:
        model_weights= {'W_FC1':(W_fc1), 'B_FC1':B_fc1, 'W_FC2':np.transpose(W_fc2), 'B_FC2':B_fc2}
    
    
    Spectral_matrix = bounds_spectral(model_weights, FLAGS)
    Fro_matrix = bounds_fro(model_weights, FLAGS)
    
    ## Returns the logits as numpy files
    Logits= compute_logits(X_test, Y_test, FLAGS)

    # ## Compute  and save for range of epsilon 
    for e in Epsilon:
        if(FLAGS.reg_type == "first_order"):
            Sdp_loss_01, Sdp_loss_hinge, Sdp_new_labels = compute_loss(Y_test, Logits, SDP_matrix, e, FLAGS)
        Spectral_loss_01, Spectral_loss_hinge, Spectral_new_labels = compute_loss(Y_test, Logits, Spectral_matrix, e, FLAGS)
        Fro_loss_01, Fro_loss_hinge, Fro_new_labels = compute_loss(Y_test, Logits, Fro_matrix, e, FLAGS)
    

    ## Save here (indexed by epsilon)
    os.mkdir(FLAGS.results_dir)
    
        if(FLAGS.reg_type == "first_order"):
            np.save(os.path.join(FLAGS.results_dir, 'SDP-01-' + str(e)),  Sdp_loss_01)
            np.save(os.path.join(FLAGS.results_dir, 'SDP-hinge-' + str(e)), Sdp_loss_hinge)
            np.save(os.path.join(FLAGS.results_dir, 'SDP-new-labels' + str(e)), Sdp_new_labels)

        
        np.save(os.path.join(FLAGS.results_dir, 'Spectral-01-' + str(e)), Spectral_loss_01)
        np.save(os.path.join(FLAGS.results_dir, 'Spectral-hinge-' + str(e)), Spectral_loss_hinge)
        np.save(os.path.join(FLAGS.results_dir, 'Spectral-new-labels' + str(e)), Spectral_new_labels)

 
        np.save(os.path.join(FLAGS.results_dir, 'Fro-01-' + str(e)), Fro_loss_01)
        np.save(os.path.join(FLAGS.results_dir, 'Fro-hinge-' + str(e)), Fro_loss_hinge)
        np.save(os.path.join(FLAGS.results_dir, 'Fro-new-labels' + str(e)), Fro_new_labels)

    
